python3 baseline.py --data_format sbert --split random --dataset cora --lr 0.01 --seed_num 5

python3 baseline.py --data_format sbert_updated --split random --dataset history --lr 0.01 --seed_num 5


python3 baseline.py 
--data_format sbert 
--split random 
--dataset pubmed 
--lr 0.01 
--seed_num 5


# Track Results
### Random - High Label Setting ###
Sbert lr 0.01 random - 
Test Accuracy: 82.54 ± 1.01
Test acc: [0.8305709023941068, 0.8121546961325967, 0.8158379373848987, 0.8397790055248618, 0.8287292817679558]

Mistral lr 0.01 random - 
Test Accuracy: 77.27 ± 6.59
Test acc: [0.714548802946593, 0.8268876611418048, 0.8103130755064457, 0.6740331491712708, 0.8379373848987108]

Mixedbread lr 0.01 random -
Test Accuracy: 84.05 ± 1.04
Test acc: [0.8342541436464088, 0.848987108655617, 0.8342541436464088, 0.856353591160221, 0.8287292817679558]

Gist_small lr 0.01 random - 
Test Accuracy: 82.91 ± 0.72
Test acc: [0.8250460405156538, 0.8250460405156538, 0.8213627992633518, 0.8416206261510129, 0.8324125230202578]

tfidf
Test Accuracy: 81.07 ± 1.41
Test acc: [0.8195211786372008, 0.7826887661141805, 0.8158379373848987, 0.8195211786372008, 0.8158379373848987]

Word2Vec
Test Accuracy: 71.60 ± 2.24
Test acc: [0.7016574585635359, 0.6887661141804788, 0.7071823204419889, 0.7311233885819521, 0.7513812154696132]

e5-Large
Test Accuracy: 82.21 ± 1.67
Test acc: [0.8029465930018416, 0.8066298342541437, 0.8434622467771639, 0.8397790055248618, 0.8176795580110497]

e5-small
Test Accuracy: 82.47 ± 0.63
Test acc: [0.8232044198895028, 0.8158379373848987, 0.8342541436464088, 0.8287292817679558, 0.8213627992633518]

sbert_extra_embed
Test Accuracy: 91.30 ± 0.55
Test acc: [0.9182785299806576, 0.9163442940038685, 0.9115087040618955, 0.9158607350096711, 0.9028046421663443]


### FIXED - Low Label Setting####

Mixedbread lr 0.01 fixed -
Test Accuracy: 75.25 ± 1.61
Test acc: [0.7393617021276596, 0.761605415860735, 0.7287234042553191, 0.7596711798839458, 0.77321083172147]

Sbert_Updated lr 0.01 fixed - 
Test Accuracy: 73.22 ± 1.36
Test acc: [0.7205029013539652, 0.7238878143133463, 0.7190522243713733, 0.7480657640232108, 0.7495164410058027]

Mistral lr 0.01 fixed -
Test Accuracy: 74.14 ± 2.17
Test acc: [0.7591876208897486, 0.7620889748549323, 0.7156673114119922, 0.7558027079303675, 0.7142166344294004]

Gist_small lr 0.01 fixed -
Test Accuracy: 73.88 ± 2.14
Test acc: [0.7432301740812379, 0.7412959381044487, 0.6982591876208898, 0.7606382978723404, 0.7504835589941973]


KEA Random E5 0.01
Test Accuracy: 80.29 ± 0.84
Test acc: [0.8029465930018416, 0.8029465930018416, 0.7882136279926335, 0.8139963167587477, 0.8066298342541437]

KEA Fixed E5 0.01
Test Accuracy: 68.40 ± 2.11
Test acc: [0.7064796905222437, 0.6929400386847195, 0.6441005802707931, 0.6856866537717602, 0.6910058027079303]

sbert_extra_embed
Test Accuracy: 82.90 ± 0.90
Test acc: [0.8404255319148937, 0.8351063829787234, 0.8317214700193424, 0.8225338491295938, 0.8152804642166345]

Experiments to Run
Type-1 (GCN, GAT, MLP, GraphSage)
tfidf - Random and Fixed
Word2Vec - Random and Fixed
Sbert - Random and Fixed
Mistral - Random and Fixed
Mixedbread - Random and Fixed
Gist_small - Random and Fixed
Llama - Random and Fixed



Experiment Levels for Type-2
Already - 2(random vs fixed) * 3 (GCN, GAT, MLP) - 6
1) Appending Stage -> Either at Text Level or at Embedding Level - 2
2) Combination fo TAPE and KIA (TAPE+KIA, TA + KEA!!, KEA!!, PE!!, TAPE) - 4
3) Differnet types of Models for Embeddings- (sbert, e5-small, Mistral) - 2




# Generating the first level Embedding
# change line 158's name to the desired name before running this command
python3 baseline.py --data_format tfidf --split random --model_name GCN --dataset cora --lr 0.01 --seed_num 5

python3 baseline.py --data_format tfidf --split fixed --model_name GCN --dataset cora --lr 0.01 --seed_num 5

python3 baseline.py --data_format sbert_extra_embed --split random --dataset cora --lr 0.01 --seed_num 5

python3 baseline.py --data_format sbert_extra_embed --split fixed --dataset cora --lr 0.01 --seed_num 5

python3 baseline.py --data_format tfidf --split random --model_name GCN --dataset citeseer --lr 0.01 --seed_num 5





## Random Increasing Layer

Random Split
Num Layer - 2 
MLP - 91.45 ± 2.57
GCN - 89.61 ± 1.64
GAT - 90.31 ± 1.64

Num Layer - 3
MLP - 90.87 ± 2.35
GCN - 88.55 ± 0.96
GAT - 90.35 ± 1.89

Num Layer - 4
MLP - 90.83 ± 2.32
GCN - 88.47 ± 0.86
GAT - 89.83 ± 1.72


Num Layer - 5
MLP - 90.61 ± 2.25
GCN - 87.92 ± 1.22
GAT - 88.73 ± 2.16

Num Layer - 6
MLP - 89.76 ± 1.97
GCN - 87.73 ± 1.26
GAT - 89.10 ± 1.40



Fixed Split

Num Layer - 2
MLP - 82.67 ± 1.21
GCN - 83.02 ± 0.87
GAT - 83.36 ± 0.96

Num Layer - 3
MLP - 82.01 ± 0.69
GCN - 82.16 ± 1.08
GAT - 81.97 ± 1.20

Num Layer - 4
MLP - 81.18 ± 1.51
GCN - 81.19 ± 0.95
GAT - 81.34 ± 1.29

Num Layer - 5
MLP - 80.42 ± 1.19
GCN - 80.92 ± 0.97
GAT - 79.36 ± 1.25

Num Layer - 6
MLP - 78.52 ± 1.29
GCN - 79.27 ± 1.60
GAT - 76.56 ± 0.96



