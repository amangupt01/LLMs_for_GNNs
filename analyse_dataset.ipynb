{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_data/ogb_arxiv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All citations:\")\n",
    "for citation in data_edge_index.t().tolist():\n",
    "    print(citation)\n",
    "\n",
    "# Finding unique citations\n",
    "unique_citations = set(tuple(c) for c in data_edge_index.t().tolist())\n",
    "\n",
    "# Printing unique citations\n",
    "print(\"\\nUnique citations:\")\n",
    "for citation in unique_citations:\n",
    "    print(citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(f\"preprocessed_data/new/cora_random_sbert.pt\", map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse the data\n",
    "print(data, type(data))\n",
    "print(data.label_names)\n",
    "\n",
    "print(data.raw_text[0]) # raw text is title: abstract\n",
    "\n",
    "print(data.y[0]) # label\n",
    "print(data.y.unique())\n",
    "\n",
    "# print(data.edge_index[:,5]) # edge index\n",
    "print(data.train_masks) # train mask\n",
    "print(data.train_masks[0].shape)\n",
    "print(sum(data.train_masks[0]),sum(data.train_masks[6])) # train mask\n",
    "print(data.val_masks) # val mask\n",
    "print(data.test_masks) # test mask\n",
    "\n",
    "print(data.x[0].shape) # x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(data.edge_index.shape[1]):\n",
    "    curr = tuple(data.edge_index[:,i].numpy())\n",
    "    if curr in d:\n",
    "        d[curr] += 1\n",
    "    else:\n",
    "        d[curr] = 1\n",
    "unique_edges = set()\n",
    "for k in d.keys():\n",
    "    curr = tuple(sorted(list(k)))\n",
    "    unique_edges.add(curr)\n",
    "print(\"Number of unique edges\",len(unique_edges))\n",
    "print(set(d.values()))\n",
    "print(len(d))\n",
    "# most of the edges are repeated twice but it should be a directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(f\"preprocessed_data/new/cora_random_sbert.pt\", map_location='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(raw_text=[2708], y=[2708], label_names=[7], edge_index=[2, 10858], train_masks=[10], val_masks=[10], test_masks=[10], x=[2708, 384], raw_texts=[2708], category_names=[2708]) <class 'torch_geometric.data.data.Data'>\n",
      "['Rule_Learning', 'Neural_Networks', 'Case_Based', 'Genetic_Algorithms', 'Theory', 'Reinforcement_Learning', 'Probabilistic_Methods']\n",
      " Stochastic pro-positionalization of non-determinate background knowledge. : It is a well-known fact that propositional learning algorithms require \"good\" features to perform well in practice. So a major step in data engineering for inductive learning is the construction of good features by domain experts. These features often represent properties of structured objects, where a property typically is the occurrence of a certain substructure having certain properties. To partly automate the process of \"feature engineering\", we devised an algorithm that searches for features which are defined by such substructures. The algorithm stochastically conducts a top-down search for first-order clauses, where each clause represents a binary feature. It differs from existing algorithms in that its search is not class-blind, and that it is capable of considering clauses (\"context\") of almost arbitrary length (size). Preliminary experiments are favorable, and support the view that this approach is promising.\n",
      "tensor(0)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "[tensor([False,  True,  True,  ...,  True,  True,  True]), tensor([ True,  True,  True,  ...,  True, False,  True]), tensor([ True,  True, False,  ..., False,  True, False]), tensor([False,  True, False,  ...,  True,  True, False]), tensor([ True, False,  True,  ..., False, False,  True]), tensor([False,  True,  True,  ..., False,  True, False]), tensor([False,  True, False,  ..., False, False,  True]), tensor([ True, False,  True,  ...,  True,  True,  True]), tensor([ True,  True,  True,  ..., False, False,  True]), tensor([ True,  True, False,  ...,  True, False,  True])]\n",
      "torch.Size([2708])\n",
      "tensor(1624) tensor(1624)\n",
      "[tensor([ True, False, False,  ..., False, False, False]), tensor([False, False, False,  ..., False,  True, False]), tensor([False, False,  True,  ..., False, False,  True]), tensor([False, False, False,  ..., False, False, False]), tensor([False,  True, False,  ...,  True,  True, False]), tensor([False, False, False,  ..., False, False,  True]), tensor([False, False,  True,  ...,  True,  True, False]), tensor([False, False, False,  ..., False, False, False]), tensor([False, False, False,  ...,  True, False, False]), tensor([False, False, False,  ..., False,  True, False])]\n",
      "[tensor([False, False, False,  ..., False, False, False]), tensor([False, False, False,  ..., False, False, False]), tensor([False, False, False,  ...,  True, False, False]), tensor([ True, False,  True,  ..., False, False,  True]), tensor([False, False, False,  ..., False, False, False]), tensor([ True, False, False,  ...,  True, False, False]), tensor([ True, False, False,  ..., False, False, False]), tensor([False,  True, False,  ..., False, False, False]), tensor([False, False, False,  ..., False,  True, False]), tensor([False, False,  True,  ..., False, False, False])]\n",
      "torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "# analyse the data\n",
    "print(data, type(data))\n",
    "print(data.label_names)\n",
    "\n",
    "print(data.raw_text[0]) # raw text is title: abstract\n",
    "\n",
    "print(data.y[0]) # label\n",
    "print(data.y.unique())\n",
    "\n",
    "# print(data.edge_index[:,5]) # edge index\n",
    "print(data.train_masks) # train mask\n",
    "print(data.train_masks[0].shape)\n",
    "print(sum(data.train_masks[0]),sum(data.train_masks[6])) # train mask\n",
    "print(data.val_masks) # val mask\n",
    "print(data.test_masks) # test mask\n",
    "\n",
    "print(data.x[0].shape) # x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10858])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique edges 5278\n",
      "{1, 2}\n",
      "10556\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for i in range(data.edge_index.shape[1]):\n",
    "    curr = tuple(data.edge_index[:,i].numpy())\n",
    "    if curr in d:\n",
    "        d[curr] += 1\n",
    "    else:\n",
    "        d[curr] = 1\n",
    "unique_edges = set()\n",
    "for k in d.keys():\n",
    "    curr = tuple(sorted(list(k)))\n",
    "    unique_edges.add(curr)\n",
    "print(\"Number of unique edges\",len(unique_edges))\n",
    "print(set(d.values()))\n",
    "print(len(d))\n",
    "# most of the edges are repeated twice but it should be a directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amangupt/anaconda3/envs/pgm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "\n",
    "# Access the graph data\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(f\"preprocessed_data/new/cora_random_mistral.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(raw_text=[2708], y=[2708], label_names=[7], edge_index=[2, 10858], train_masks=[10], val_masks=[10], test_masks=[10], x=[2708, 4096], raw_texts=[2708], category_names=[2708], entity=[2708]) <class 'torch_geometric.data.data.Data'>\n",
      "['Rule_Learning', 'Neural_Networks', 'Case_Based', 'Genetic_Algorithms', 'Theory', 'Reinforcement_Learning', 'Probabilistic_Methods']\n",
      " Stochastic pro-positionalization of non-determinate background knowledge. : It is a well-known fact that propositional learning algorithms require \"good\" features to perform well in practice. So a major step in data engineering for inductive learning is the construction of good features by domain experts. These features often represent properties of structured objects, where a property typically is the occurrence of a certain substructure having certain properties. To partly automate the process of \"feature engineering\", we devised an algorithm that searches for features which are defined by such substructures. The algorithm stochastically conducts a top-down search for first-order clauses, where each clause represents a binary feature. It differs from existing algorithms in that its search is not class-blind, and that it is capable of considering clauses (\"context\") of almost arbitrary length (size). Preliminary experiments are favorable, and support the view that this approach is promising.\n",
      "tensor(0)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6])\n",
      "[tensor([False,  True,  True,  ...,  True,  True,  True]), tensor([ True,  True,  True,  ...,  True, False,  True]), tensor([ True,  True, False,  ..., False,  True, False]), tensor([False,  True, False,  ...,  True,  True, False]), tensor([ True, False,  True,  ..., False, False,  True]), tensor([False,  True,  True,  ..., False,  True, False]), tensor([False,  True, False,  ..., False, False,  True]), tensor([ True, False,  True,  ...,  True,  True,  True]), tensor([ True,  True,  True,  ..., False, False,  True]), tensor([ True,  True, False,  ...,  True, False,  True])]\n",
      "torch.Size([2708])\n",
      "tensor(1624) tensor(1624)\n",
      "[tensor([ True, False, False,  ..., False, False, False]), tensor([False, False, False,  ..., False,  True, False]), tensor([False, False,  True,  ..., False, False,  True]), tensor([False, False, False,  ..., False, False, False]), tensor([False,  True, False,  ...,  True,  True, False]), tensor([False, False, False,  ..., False, False,  True]), tensor([False, False,  True,  ...,  True,  True, False]), tensor([False, False, False,  ..., False, False, False]), tensor([False, False, False,  ...,  True, False, False]), tensor([False, False, False,  ..., False,  True, False])]\n",
      "[tensor([False, False, False,  ..., False, False, False]), tensor([False, False, False,  ..., False, False, False]), tensor([False, False, False,  ...,  True, False, False]), tensor([ True, False,  True,  ..., False, False,  True]), tensor([False, False, False,  ..., False, False, False]), tensor([ True, False, False,  ...,  True, False, False]), tensor([ True, False, False,  ..., False, False, False]), tensor([False,  True, False,  ..., False, False, False]), tensor([False, False, False,  ..., False,  True, False]), tensor([False, False,  True,  ..., False, False, False])]\n",
      "torch.Size([4096])\n"
     ]
    }
   ],
   "source": [
    "# analyse the data\n",
    "print(data, type(data))\n",
    "print(data.label_names)\n",
    "\n",
    "print(data.raw_text[0]) # raw text is title: abstract\n",
    "\n",
    "print(data.y[0]) # label\n",
    "print(data.y.unique())\n",
    "\n",
    "# print(data.edge_index[:,5]) # edge index\n",
    "print(data.train_masks) # train mask\n",
    "print(data.train_masks[0].shape)\n",
    "print(sum(data.train_masks[0]),sum(data.train_masks[6])) # train mask\n",
    "print(data.val_masks) # val mask\n",
    "print(data.test_masks) # test mask\n",
    "\n",
    "print(data.x[0].shape) # x\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMGNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
